#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""RAT QuickDB Python MongoDB ç¼“å­˜æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹

æœ¬ç¤ºä¾‹å¯¹æ¯”å¯ç”¨ç¼“å­˜å’Œæœªå¯ç”¨ç¼“å­˜çš„MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½å·®å¼‚
ä½¿ç”¨ MongoDB æ•°æ®åº“è¿›è¡Œæµ‹è¯•ï¼Œæ”¯æŒ TLSã€è®¤è¯å’Œ ZSTD å‹ç¼©

åŸºäº SQLite ç‰ˆæœ¬çš„ç¼“å­˜æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹æ”¹å†™ä¸º MongoDB ç‰ˆæœ¬
"""

import json
import time
import os
import shutil
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

# å¯¼å…¥ä¼˜é›…å…³é—­æœºåˆ¶
from graceful_shutdown import GracefulShutdownMixin, ShutdownConfig, with_graceful_shutdown

# å…¨å±€å˜é‡ç”¨äºä¼˜é›…å…³é—­
import signal
import threading
shutdown_requested = False
test_instance = None
shutdown_lock = threading.Lock()
shutdown_timeout = 15  # å¼ºåˆ¶é€€å‡ºè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

def force_exit():
    """å¼ºåˆ¶é€€å‡ºå‡½æ•°"""
    print(f"âš ï¸ ä¼˜é›…å…³é—­è¶…æ—¶ï¼ˆ{shutdown_timeout}ç§’ï¼‰ï¼Œå¼ºåˆ¶é€€å‡ºç¨‹åº")
    import os
    os._exit(1)

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    global shutdown_requested, test_instance
    
    with shutdown_lock:
        if shutdown_requested:
            print(f"\nğŸ›‘ å†æ¬¡æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼ºåˆ¶é€€å‡º...")
            force_exit()
            return
        
        shutdown_requested = True
        print(f"\nğŸ›‘ æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        
        # å¯åŠ¨å¼ºåˆ¶é€€å‡ºå®šæ—¶å™¨
        timer = threading.Timer(shutdown_timeout, force_exit)
        timer.daemon = True
        timer.start()
        
        if test_instance:
            try:
                print("ğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")
                test_instance.shutdown()
                timer.cancel()  # å–æ¶ˆå¼ºåˆ¶é€€å‡ºå®šæ—¶å™¨
                print("ğŸ‘‹ ç¨‹åºå·²ä¼˜é›…å…³é—­")
                import sys
                sys.exit(0)
            except Exception as e:
                print(f"âš ï¸ å…³é—­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                timer.cancel()
                force_exit()
        else:
            timer.cancel()
            print("ğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            import sys
            sys.exit(0)

try:
    import rat_quickdb_py
    from rat_quickdb_py import (
        create_db_queue_bridge,
        get_version,
        get_info,
        get_name,
        PyCacheConfig,
        PyL1CacheConfig,
        PyL2CacheConfig,
        PyTtlConfig,
        PyCompressionConfig,
        PyTlsConfig,
        PyZstdConfig,
    )
except ImportError as e:
    print(f"é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ rat_quickdb_py æ¨¡å—: {e}")
    print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… rat-quickdb-py åŒ…")
    print("å®‰è£…å‘½ä»¤ï¼šmaturin develop")
    exit(1)


@dataclass
class TestUser:
    """æµ‹è¯•ç”¨æˆ·æ•°æ®ç»“æ„"""
    id: str
    name: str
    email: str
    age: int
    created_at: str
    
    @classmethod
    def new(cls, user_id: str, name: str, email: str, age: int) -> 'TestUser':
        return cls(
            id=user_id,
            name=name,
            email=email,
            age=age,
            created_at=datetime.now(timezone.utc).isoformat()
        )
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps({
            "id": self.id,  # ç»Ÿä¸€ä½¿ç”¨idå­—æ®µï¼ŒODMè‡ªåŠ¨å¤„ç†MongoDBçš„_idæ˜ å°„
            "name": self.name,
            "email": self.email,
            "age": self.age,
            "created_at": self.created_at
        })


@dataclass
class PerformanceResult:
    """æ€§èƒ½æµ‹è¯•ç»“æœ"""
    operation: str
    with_cache: float  # æ¯«ç§’
    without_cache: float  # æ¯«ç§’
    improvement_ratio: float
    cache_hit_rate: Optional[float] = None
    
    @classmethod
    def new(cls, operation: str, with_cache: float, without_cache: float) -> 'PerformanceResult':
        improvement_ratio = without_cache / with_cache if with_cache > 0 else 1.0
        return cls(
            operation=operation,
            with_cache=with_cache,
            without_cache=without_cache,
            improvement_ratio=improvement_ratio
        )
    
    def with_cache_hit_rate(self, hit_rate: float) -> 'PerformanceResult':
        self.cache_hit_rate = hit_rate
        return self


class MongoDbCachePerformanceTest(GracefulShutdownMixin):
    """MongoDBç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    
    @staticmethod
    def get_ca_cert_path():
        """è·å–è·¨å¹³å°çš„CAè¯ä¹¦è·¯å¾„"""
        import platform
        import os
        
        system = platform.system().lower()
        
        if system == "darwin":  # macOS
            # macOSç³»ç»ŸCAè¯ä¹¦è·¯å¾„
            ca_paths = [
                "/etc/ssl/cert.pem",
                "/usr/local/etc/openssl/cert.pem",
                "/opt/homebrew/etc/openssl/cert.pem"
            ]
        elif system == "linux":
            # Linuxç³»ç»ŸCAè¯ä¹¦è·¯å¾„
            ca_paths = [
                "/etc/ssl/certs/ca-certificates.crt",  # Debian/Ubuntu
                "/etc/pki/tls/certs/ca-bundle.crt",    # RHEL/CentOS
                "/etc/ssl/ca-bundle.pem",              # SUSE
                "/etc/ssl/cert.pem"                     # Alpine
            ]
        elif system == "windows":
            # Windowsä½¿ç”¨ç³»ç»Ÿè¯ä¹¦å­˜å‚¨ï¼Œä¸éœ€è¦æ–‡ä»¶è·¯å¾„
            return None
        else:
            # å…¶ä»–ç³»ç»Ÿå°è¯•å¸¸è§è·¯å¾„
            ca_paths = [
                "/etc/ssl/certs/ca-certificates.crt",
                "/etc/ssl/cert.pem"
            ]
        
        # æŸ¥æ‰¾å­˜åœ¨çš„CAè¯ä¹¦æ–‡ä»¶
        for path in ca_paths:
            if os.path.exists(path):
                return path
        
        # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›Noneï¼ˆä½¿ç”¨ç³»ç»Ÿé»˜è®¤ï¼‰
        return None
    
    def __init__(self):
        # åˆå§‹åŒ–ä¼˜é›…å…³é—­æœºåˆ¶ï¼Œå‡å°‘è¶…æ—¶æ—¶é—´é˜²æ­¢æ— é™ç­‰å¾…
        super().__init__(ShutdownConfig(
            shutdown_timeout=10,  # å‡å°‘å…³é—­è¶…æ—¶æ—¶é—´åˆ°10ç§’
            verbose_logging=True,
            auto_cleanup_on_exit=True
        ))
        
        self.bridge = None
        self.results: List[PerformanceResult] = []
        self.test_data_dir = "./test_data"
        # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºé›†åˆååç¼€ï¼Œé¿å…é‡å¤
        timestamp = int(time.time() * 1000)
        self.collection_name = f"test_users_{timestamp}"
        
        # æ³¨å†Œä¸´æ—¶ç›®å½•
        self.add_temp_dir(self.test_data_dir)
    
    def _cleanup_existing_collections(self):
        """æ¸…ç†ç°æœ‰çš„æµ‹è¯•é›†åˆ"""
        print("ğŸ§¹ æ¸…ç†ç°æœ‰çš„æµ‹è¯•é›†åˆ...")
        try:
            # åˆ›å»ºä¸´æ—¶æ•°æ®åº“è¿æ¥ç”¨äºæ¸…ç† - ä¸ä½¿ç”¨ç¼“å­˜é¿å…é”å†²çª
            cache_config = None  # ä¸ä½¿ç”¨ç¼“å­˜ï¼Œé¿å…ä¸åç»­çš„ç¼“å­˜æ•°æ®åº“äº§ç”Ÿé”å†²çª
            tls_config = PyTlsConfig()
            tls_config.enable()
            
            ca_cert_path = self.get_ca_cert_path()
            if ca_cert_path:
                tls_config.ca_cert_path = ca_cert_path
            
            zstd_config = PyZstdConfig()
            zstd_config.disable()  # æ¸…ç†æ—¶ç¦ç”¨å‹ç¼©ï¼Œæé«˜é€Ÿåº¦
            
            self.bridge.add_mongodb_database(
                alias="cleanup_temp",
                host="db0.0ldm0s.net",
                port=27017,
                database="testdb",
                username="testdb",
                password="yash2vCiBA&B#h$#i&gb@IGSTh&cP#QC^",
                auth_source="testdb",
                direct_connection=True,
                max_connections=2,
                min_connections=1,
                connection_timeout=5,
                idle_timeout=60,
                max_lifetime=300,
                cache_config=cache_config,  # ä¸ä½¿ç”¨ç¼“å­˜
                tls_config=tls_config,
                zstd_config=zstd_config
            )
            
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æµ‹è¯•é›†åˆ
            collections_to_clean = ["test_users", "users", "performance_test", self.collection_name]
            for collection in collections_to_clean:
                try:
                    self.bridge.drop_table(collection, "cleanup_temp")
                    print(f"âœ… å·²æ¸…ç†é›†åˆ: {collection}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†é›†åˆ {collection} æ—¶å‡ºé”™: {e}")
            
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ç°æœ‰é›†åˆæ—¶å‡ºé”™: {e}")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸš€ åˆå§‹åŒ–MongoDBç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•ç¯å¢ƒ...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
            os.makedirs(self.test_data_dir, exist_ok=True)
            
            # åˆ›å»ºæ•°æ®åº“é˜Ÿåˆ—æ¡¥æ¥å™¨
            self.bridge = create_db_queue_bridge()
            self.add_database_connection(self.bridge)
            
            # æ¸…ç†ç°æœ‰çš„æµ‹è¯•é›†åˆ
            self._cleanup_existing_collections()
            
            # æ·»åŠ å¸¦ç¼“å­˜çš„MongoDBæ•°æ®åº“
            self._add_cached_mongodb_database()
            
            # æ·»åŠ ä¸å¸¦ç¼“å­˜çš„MongoDBæ•°æ®åº“
            self._add_non_cached_mongodb_database()
            
            print("âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _create_cached_config(self) -> PyCacheConfig:
        """åˆ›å»ºå¸¦ç¼“å­˜çš„é…ç½®ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        cache_config = PyCacheConfig()
        cache_config.enable()
        cache_config.strategy = "lru"
        
        # L1ç¼“å­˜é…ç½® - é€‚é…ç³»ç»Ÿå†…å­˜é™åˆ¶
        l1_config = PyL1CacheConfig(5000)  # 5000æ¡è®°å½•
        l1_config.max_memory_mb = 100  # 100MBå†…å­˜ï¼Œé€‚é…ç³»ç»Ÿé™åˆ¶
        l1_config.enable_stats = False  # ç¦ç”¨ç»Ÿè®¡ä»¥å‡å°‘å¼€é”€
        cache_config.l1_config = l1_config
        
        # L2ç¼“å­˜é…ç½® - åˆç†çš„ç£ç›˜å®¹é‡é…ç½®
        l2_config = PyL2CacheConfig(f"{self.test_data_dir}/mongodb_cache_test")
        l2_config.max_disk_mb = 1000  # 1GBç£ç›˜ç©ºé—´
        l2_config.compression_level = 1  # æœ€ä½å‹ç¼©çº§åˆ«ä»¥æœ€å¤§åŒ–æ€§èƒ½
        l2_config.enable_wal = False  # ç¦ç”¨WALä»¥å‡å°‘ç£ç›˜I/Oå¼€é”€
        l2_config.clear_on_startup = False  # å¯åŠ¨æ—¶ä¸æ¸…ç©ºç¼“å­˜ç›®å½•
        # æ³¨æ„ï¼šL2ç¼“å­˜å¯èƒ½ä¸æ”¯æŒç¦ç”¨ç»Ÿè®¡åŠŸèƒ½
        cache_config.l2_config = l2_config
        
        # TTLé…ç½® - å»¶é•¿ç¼“å­˜æ—¶é—´ç¡®ä¿æµ‹è¯•æœŸé—´ä¸è¿‡æœŸ
        ttl_config = PyTtlConfig(3600)  # å¢åŠ åˆ°1å°æ—¶TTL
        ttl_config.max_ttl_secs = 14400  # å¢åŠ åˆ°4å°æ—¶æœ€å¤§TTL
        ttl_config.check_interval_secs = 600  # å¢åŠ æ£€æŸ¥é—´éš”åˆ°10åˆ†é’Ÿ
        cache_config.ttl_config = ttl_config
        
        # å‹ç¼©é…ç½® - ç¦ç”¨å‹ç¼©ä»¥å‡å°‘CPUå¼€é”€
        compression_config = PyCompressionConfig("zstd")
        compression_config.enabled = False  # ç¦ç”¨å‹ç¼©ä»¥å‡å°‘CPUå¼€é”€
        compression_config.threshold_bytes = 1024
        cache_config.compression_config = compression_config
        
        print("  ğŸ“Š ç¼“å­˜é…ç½®: L1(5000æ¡/100MB) + L2(1GB) + TTL(1å°æ—¶) + é›¶å¼€é”€ä¼˜åŒ–")
        return cache_config
    
    def _add_cached_mongodb_database(self):
        """æ·»åŠ å¸¦ç¼“å­˜çš„MongoDBæ•°æ®åº“"""
        cache_config = self._create_cached_config()
        
        # TLSé…ç½®ï¼ˆå¯ç”¨ï¼‰
        tls_config = PyTlsConfig()
        tls_config.enable()  # å¯ç”¨TLSè¿æ¥
        
        # è·¨å¹³å°CAè¯ä¹¦è·¯å¾„æ£€æµ‹
        ca_cert_path = self.get_ca_cert_path()
        if ca_cert_path:
            tls_config.ca_cert_path = ca_cert_path
            print(f"  ğŸ”’ ä½¿ç”¨CAè¯ä¹¦è·¯å¾„: {ca_cert_path}")
        else:
            print("  ğŸ”’ ä½¿ç”¨ç³»ç»Ÿé»˜è®¤CAè¯ä¹¦å­˜å‚¨")
            
        tls_config.client_cert_path = ""
        tls_config.client_key_path = ""
        
        # ZSTDå‹ç¼©é…ç½®ï¼ˆå¯é€‰ï¼‰
        zstd_config = PyZstdConfig()
        zstd_config.enable()  # å¯ç”¨ZSTDå‹ç¼©
        zstd_config.compression_level = 3
        zstd_config.compression_threshold = 1024
        
        response = self.bridge.add_mongodb_database(
            alias="mongodb_cached",
            host="db0.0ldm0s.net",
            port=27017,
            database="testdb",
            username="testdb",
            password="yash2vCiBA&B#h$#i&gb@IGSTh&cP#QC^",
            auth_source="testdb",
            direct_connection=True,
            max_connections=10,
            min_connections=2,
            connection_timeout=5,  # å‡å°‘è¿æ¥è¶…æ—¶æ—¶é—´åˆ°5ç§’
            idle_timeout=60,       # å‡å°‘ç©ºé—²è¶…æ—¶æ—¶é—´åˆ°1åˆ†é’Ÿ
            max_lifetime=300,      # å‡å°‘æœ€å¤§ç”Ÿå‘½å‘¨æœŸåˆ°5åˆ†é’Ÿ
            cache_config=cache_config,  # None - çœŸæ­£ä¸ä½¿ç”¨ç¼“å­˜
            tls_config=tls_config,
            zstd_config=zstd_config
        )
        
        result = json.loads(response)
        if not result.get("success"):
            raise Exception(f"æ·»åŠ ç¼“å­˜MongoDBæ•°æ®åº“å¤±è´¥: {result.get('error')}")
    
    def _add_non_cached_mongodb_database(self):
        """æ·»åŠ ä¸å¸¦ç¼“å­˜çš„MongoDBæ•°æ®åº“"""
        # çœŸæ­£çš„æ— ç¼“å­˜é…ç½®ï¼šä¸åˆ›å»ºä»»ä½•ç¼“å­˜ç®¡ç†å™¨
        cache_config = None
        
        # TLSé…ç½®ï¼ˆå¯ç”¨ï¼‰
        tls_config = PyTlsConfig()
        tls_config.enable()  # å¯ç”¨TLSè¿æ¥
        
        # è·¨å¹³å°CAè¯ä¹¦è·¯å¾„æ£€æµ‹
        ca_cert_path = self.get_ca_cert_path()
        if ca_cert_path:
            tls_config.ca_cert_path = ca_cert_path
            print(f"  ğŸ”’ éç¼“å­˜æ•°æ®åº“ä½¿ç”¨CAè¯ä¹¦è·¯å¾„: {ca_cert_path}")
        else:
            print("  ğŸ”’ éç¼“å­˜æ•°æ®åº“ä½¿ç”¨ç³»ç»Ÿé»˜è®¤CAè¯ä¹¦å­˜å‚¨")
            
        tls_config.client_cert_path = ""
        tls_config.client_key_path = ""
        
        # ZSTDå‹ç¼©é…ç½®ï¼ˆç¦ç”¨ï¼‰
        zstd_config = PyZstdConfig()
        zstd_config.disable()  # ç¦ç”¨ZSTDå‹ç¼©
        
        response = self.bridge.add_mongodb_database(
            alias="mongodb_non_cached",
            host="db0.0ldm0s.net",
            port=27017,
            database="testdb",
            username="testdb",
            password="yash2vCiBA&B#h$#i&gb@IGSTh&cP#QC^",
            auth_source="testdb",
            direct_connection=True,
            max_connections=10,
            min_connections=2,
            connection_timeout=5,  # å‡å°‘è¿æ¥è¶…æ—¶æ—¶é—´åˆ°5ç§’
            idle_timeout=60,       # å‡å°‘ç©ºé—²è¶…æ—¶æ—¶é—´åˆ°1åˆ†é’Ÿ
            max_lifetime=300,      # å‡å°‘æœ€å¤§ç”Ÿå‘½å‘¨æœŸåˆ°5åˆ†é’Ÿ
            cache_config=cache_config,
            tls_config=tls_config,
            zstd_config=zstd_config
        )
        
        result = json.loads(response)
        if not result.get("success"):
            raise Exception(f"æ·»åŠ éç¼“å­˜MongoDBæ•°æ®åº“å¤±è´¥: {result.get('error')}")
    
    def setup_test_data(self) -> bool:
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        print("\nğŸ”§ è®¾ç½®MongoDBæµ‹è¯•æ•°æ®...")
        
        try:
            max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
            operation_timeout = 5  # å•ä¸ªæ“ä½œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
            # åŸºç¡€æµ‹è¯•ç”¨æˆ·ï¼ˆä¸ºä¸åŒæ•°æ®åº“ä½¿ç”¨ä¸åŒçš„IDå‰ç¼€é¿å…å†²çªï¼‰
            cached_users = [
                TestUser.new(f"cached_user_{i:03d}", f"ç¼“å­˜ç”¨æˆ·{i}", f"cached_user{i}@example.com", 20 + (i % 50))
                for i in range(1, 101)
            ]
            
            non_cached_users = [
                TestUser.new(f"non_cached_user_{i:03d}", f"éç¼“å­˜ç”¨æˆ·{i}", f"non_cached_user{i}@example.com", 20 + (i % 50))
                for i in range(1, 101)
            ]
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°ç¼“å­˜æ•°æ®åº“
            for i, user in enumerate(cached_users):
                retry_count = 0
                success = False
                
                while retry_count < max_retries and not success:
                    try:
                        start_time = time.time()
                        response = self.bridge.create(self.collection_name, user.to_json(), "mongodb_cached")
                        
                        # æ£€æŸ¥æ“ä½œæ˜¯å¦è¶…æ—¶
                        if time.time() - start_time > operation_timeout:
                            raise TimeoutError(f"æ“ä½œè¶…æ—¶ï¼ˆ>{operation_timeout}ç§’ï¼‰")
                        
                        result = json.loads(response)
                        if not result.get("success"):
                            raise Exception(result.get('error'))
                        
                        success = True
                        if i == 0:  # åªæ‰“å°ç¬¬ä¸€æ¡è®°å½•çš„ç»“æœ
                            print(f"  âœ… åˆ›å»ºç¼“å­˜ç”¨æˆ·æ•°æ®æˆåŠŸ")
                            
                    except Exception as e:
                        retry_count += 1
                        if retry_count >= max_retries:
                            print(f"âš ï¸ åˆ›å»ºç¼“å­˜ç”¨æˆ·æ•°æ®å¤±è´¥ï¼ˆé‡è¯•{max_retries}æ¬¡åæ”¾å¼ƒï¼‰: {e}")
                            return False
                        else:
                            print(f"âš ï¸ åˆ›å»ºç¼“å­˜ç”¨æˆ·æ•°æ®å¤±è´¥ï¼Œé‡è¯• {retry_count}/{max_retries}: {e}")
                            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°éç¼“å­˜æ•°æ®åº“
            for i, user in enumerate(non_cached_users):
                retry_count = 0
                success = False
                
                while retry_count < max_retries and not success:
                    try:
                        start_time = time.time()
                        response = self.bridge.create(self.collection_name, user.to_json(), "mongodb_non_cached")
                        
                        # æ£€æŸ¥æ“ä½œæ˜¯å¦è¶…æ—¶
                        if time.time() - start_time > operation_timeout:
                            raise TimeoutError(f"æ“ä½œè¶…æ—¶ï¼ˆ>{operation_timeout}ç§’ï¼‰")
                        
                        result = json.loads(response)
                        if not result.get("success"):
                            raise Exception(result.get('error'))
                        
                        success = True
                        if i == 0:  # åªæ‰“å°ç¬¬ä¸€æ¡è®°å½•çš„ç»“æœ
                            print(f"  âœ… åˆ›å»ºéç¼“å­˜ç”¨æˆ·æ•°æ®æˆåŠŸ")
                            
                    except Exception as e:
                        retry_count += 1
                        if retry_count >= max_retries:
                            print(f"âš ï¸ åˆ›å»ºéç¼“å­˜ç”¨æˆ·æ•°æ®å¤±è´¥ï¼ˆé‡è¯•{max_retries}æ¬¡åæ”¾å¼ƒï¼‰: {e}")
                            return False
                        else:
                            print(f"âš ï¸ åˆ›å»ºéç¼“å­˜ç”¨æˆ·æ•°æ®å¤±è´¥ï¼Œé‡è¯• {retry_count}/{max_retries}: {e}")
                            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
            
            print(f"  âœ… åˆ›å»ºäº† {len(cached_users) + len(non_cached_users)} æ¡æµ‹è¯•è®°å½•ï¼ˆæ¯ä¸ªæ•°æ®åº“{len(cached_users)}æ¡ï¼‰")
            print(f"  ğŸ“ ä½¿ç”¨é›†åˆåç§°: {self.collection_name}")
            return True
            
        except Exception as e:
            print(f"âŒ è®¾ç½®æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return False
    
    def warmup_cache(self) -> bool:
        """ç¼“å­˜é¢„çƒ­"""
        print("\nğŸ”¥ ç¼“å­˜é¢„çƒ­...")
        
        try:
            # é¢„çƒ­æŸ¥è¯¢1 - ä¸test_query_operationsä¸­çš„æŸ¥è¯¢æ¡ä»¶å®Œå…¨ä¸€è‡´
            query_conditions_1 = json.dumps([
                {"field": "age", "operator": "Gte", "value": 25},
                {"field": "age", "operator": "Lte", "value": 35},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "@example.com"}
            ])
            self.bridge.find(self.collection_name, query_conditions_1, "mongodb_cached")
            
            # é¢„çƒ­æŸ¥è¯¢2 - ä¸test_repeated_queriesä¸­çš„æŸ¥è¯¢æ¡ä»¶å®Œå…¨ä¸€è‡´
            query_conditions_2 = json.dumps([
                {"field": "age", "operator": "Gt", "value": 20},
                {"field": "age", "operator": "Lt", "value": 40},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "cached"}
            ])
            self.bridge.find(self.collection_name, query_conditions_2, "mongodb_cached")
            
            # æŒ‰IDæŸ¥è¯¢é¢„çƒ­ - é¢„çƒ­æ‰¹é‡æŸ¥è¯¢ä¸­ä¼šç”¨åˆ°çš„ID
            for i in range(1, 21):
                self.bridge.find_by_id(self.collection_name, f"cached_user_{i:03d}", "mongodb_cached")
            
            # é¢„çƒ­å¹´é¾„æŸ¥è¯¢ - é¢„çƒ­æ‰¹é‡æŸ¥è¯¢ä¸­çš„å¹´é¾„æŸ¥è¯¢
            for i in range(1, 11):
                age_conditions = json.dumps([
                    {"field": "age", "operator": "Eq", "value": 20 + (i % 50)}
                ])
                self.bridge.find(self.collection_name, age_conditions, "mongodb_cached")
            
            print("  âœ… ç¼“å­˜é¢„çƒ­å®Œæˆï¼Œé¢„çƒ­äº†æ‰€æœ‰æµ‹è¯•æŸ¥è¯¢æ¨¡å¼")
            print("  ğŸ“Š é¢„çƒ­å†…å®¹: 2ç§å¤æ‚æŸ¥è¯¢ + 20æ¡IDæŸ¥è¯¢ + 10ç§å¹´é¾„æŸ¥è¯¢")
            return True
            
        except Exception as e:
            print(f"âŒ ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
            return False
    
    def test_query_operations(self) -> bool:
        """æµ‹è¯•æŸ¥è¯¢æ“ä½œæ€§èƒ½"""
        print("\nğŸ” æµ‹è¯•MongoDBæŸ¥è¯¢æ“ä½œæ€§èƒ½...")
        
        try:
            # æ„å»ºå¤æ‚æŸ¥è¯¢æ¡ä»¶ - æŸ¥æ‰¾ç‰¹å®šç”¨æˆ·ä¸”å¹´é¾„ç¬¦åˆæ¡ä»¶
            query_conditions = json.dumps([
                {"field": "age", "operator": "Gte", "value": 25},
                {"field": "age", "operator": "Lte", "value": 35},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "@example.com"}
            ])
            
            # æµ‹è¯•ç¼“å­˜æ•°æ®åº“æŸ¥è¯¢ï¼ˆ100æ¬¡ï¼Œå¢åŠ é‡å¤æŸ¥è¯¢ä»¥ä½“ç°ç¼“å­˜ä¼˜åŠ¿ï¼‰
            start_time = time.time()
            for i in range(1, 101):
                self.bridge.find(self.collection_name, query_conditions, "mongodb_cached")
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æµ‹è¯•éç¼“å­˜æ•°æ®åº“æŸ¥è¯¢ï¼ˆ100æ¬¡ï¼‰
            start_time = time.time()
            for i in range(1, 101):
                self.bridge.find(self.collection_name, query_conditions, "mongodb_non_cached")
            non_cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            result = PerformanceResult.new(
                "å¤æ‚æŸ¥è¯¢æ“ä½œ (100æ¬¡)",
                cached_duration,
                non_cached_duration
            )
            
            print(f"  âœ… ç¼“å­˜æŸ¥è¯¢: {cached_duration:.2f}ms")
            print(f"  âœ… éç¼“å­˜æŸ¥è¯¢: {non_cached_duration:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_repeated_queries(self) -> bool:
        """æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­æµ‹è¯•ï¼‰"""
        print("\nğŸ”„ æµ‹è¯•é‡å¤æŸ¥è¯¢æ€§èƒ½ï¼ˆç¼“å­˜å‘½ä¸­æµ‹è¯•ï¼‰...")
        
        try:
            # æ„å»ºå¤šæ¡ä»¶æŸ¥è¯¢ - æŸ¥æ‰¾å¹´é¾„å¤§äº20ä¸”å§“ååŒ…å«ç‰¹å®šå­—ç¬¦çš„æ´»è·ƒç”¨æˆ·
            query_conditions = json.dumps([
                {"field": "age", "operator": "Gt", "value": 20},
                {"field": "age", "operator": "Lt", "value": 40},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "cached"}
            ])
            
            query_count = 2000  # è¿›ä¸€æ­¥å¢åŠ æŸ¥è¯¢æ¬¡æ•°ä»¥æ›´å¥½åœ°ä½“ç°ç¼“å­˜ä¼˜åŠ¿
            
            # é¦–æ¬¡æŸ¥è¯¢ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
            self.bridge.find(self.collection_name, query_conditions, "mongodb_cached")
            
            # æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆåº”è¯¥ä»ç¼“å­˜è¯»å–ï¼‰
            start_time = time.time()
            for i in range(query_count):
                self.bridge.find(self.collection_name, query_conditions, "mongodb_cached")
                # ç§»é™¤å»¶è¿Ÿä»¥è·å¾—æ›´å‡†ç¡®çš„æ€§èƒ½æµ‹è¯•ç»“æœ
            
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æµ‹è¯•éç¼“å­˜æ•°æ®åº“çš„ç›¸åŒæŸ¥è¯¢ï¼ˆæŸ¥è¯¢ç›¸åŒæ•°æ®ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
            start_time = time.time()
            for i in range(query_count):
                self.bridge.find(self.collection_name, query_conditions, "mongodb_non_cached")
                # ç§»é™¤å»¶è¿Ÿä»¥è·å¾—æ›´å‡†ç¡®çš„æ€§èƒ½æµ‹è¯•ç»“æœ
            
            non_cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # è®¡ç®—å¹³å‡å•æ¬¡æŸ¥è¯¢æ—¶é—´
            avg_cached_time = cached_duration / query_count
            avg_non_cached_time = non_cached_duration / query_count
            
            result = PerformanceResult.new(
                f"é‡å¤æŸ¥è¯¢ ({query_count}æ¬¡)",
                avg_cached_time,
                avg_non_cached_time
            ).with_cache_hit_rate(99.0)  # è¿›ä¸€æ­¥æé«˜é¢„æœŸç¼“å­˜å‘½ä¸­ç‡åˆ°99%
            
            print(f"  âœ… ç¼“å­˜æ€»è€—æ—¶: {cached_duration:.2f}ms")
            print(f"  âœ… éç¼“å­˜æ€»è€—æ—¶: {non_cached_duration:.2f}ms")
            print(f"  âœ… å¹³å‡å•æ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜ï¼‰: {avg_cached_time:.2f}ms")
            print(f"  âœ… å¹³å‡å•æ¬¡æŸ¥è¯¢ï¼ˆéç¼“å­˜ï¼‰: {avg_non_cached_time:.2f}ms")
            print(f"  ğŸ“ˆ é¢„ä¼°æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            print(f"  ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {result.cache_hit_rate:.1f}%")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ é‡å¤æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_batch_queries(self) -> bool:
        """æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½"""
        print("\nğŸ“¦ æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½...")
        
        try:
            # æµ‹è¯•ç¼“å­˜æ•°æ®åº“çš„æ‰¹é‡IDæŸ¥è¯¢
            start_time = time.time()
            for i in range(1, 21):  # æŸ¥è¯¢20ä¸ªç”¨æˆ·
                user_id = f"cached_user_{i:03d}"
                self.bridge.find_by_id(self.collection_name, user_id, "mongodb_cached")
            
            # å†è¿›è¡Œä¸€äº›å¹´é¾„èŒƒå›´æŸ¥è¯¢
            for i in range(1, 11):  # 10æ¬¡å¹´é¾„æŸ¥è¯¢
                age_conditions = json.dumps([
                    {"field": "age", "operator": "Eq", "value": 20 + (i % 50)}
                ])
                self.bridge.find(self.collection_name, age_conditions, "mongodb_cached")
            
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æµ‹è¯•éç¼“å­˜æ•°æ®åº“çš„æ‰¹é‡æŸ¥è¯¢ï¼ˆæŸ¥è¯¢ç›¸åŒçš„ç”¨æˆ·IDä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
            start_time = time.time()
            for i in range(1, 21):  # æŸ¥è¯¢20ä¸ªç”¨æˆ·
                user_id = f"cached_user_{i:03d}"  # æŸ¥è¯¢ç›¸åŒçš„ç”¨æˆ·ID
                self.bridge.find_by_id(self.collection_name, user_id, "mongodb_non_cached")
            
            # å†è¿›è¡Œä¸€äº›å¹´é¾„èŒƒå›´æŸ¥è¯¢
            for i in range(1, 11):  # 10æ¬¡å¹´é¾„æŸ¥è¯¢
                age_conditions = json.dumps([
                    {"field": "age", "operator": "Eq", "value": 20 + (i % 50)}
                ])
                self.bridge.find(self.collection_name, age_conditions, "mongodb_non_cached")
            
            non_cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            result = PerformanceResult.new(
                "æ‰¹é‡æŸ¥è¯¢ (20æ¬¡IDæŸ¥è¯¢ + 10æ¬¡å¹´é¾„æŸ¥è¯¢)",
                cached_duration,
                non_cached_duration
            )
            
            print(f"  âœ… ç¼“å­˜æ‰¹é‡æŸ¥è¯¢: {cached_duration:.2f}ms")
            print(f"  âœ… éç¼“å­˜æ‰¹é‡æŸ¥è¯¢: {non_cached_duration:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_update_operations(self) -> bool:
        """æµ‹è¯•æ›´æ–°æ“ä½œæ€§èƒ½"""
        print("\nâœï¸ æµ‹è¯•æ›´æ–°æ“ä½œæ€§èƒ½...")
        
        try:
            update_data = json.dumps({"age": 30, "updated_at": datetime.now(timezone.utc).isoformat()})
            
            # æµ‹è¯•ç¼“å­˜æ•°æ®åº“çš„æ›´æ–°æ“ä½œ
            start_time = time.time()
            for i in range(1, 11):  # æ›´æ–°10ä¸ªç”¨æˆ·
                conditions = json.dumps([
                    {"field": "_id", "operator": "Eq", "value": f"cached_user_{i:03d}"}
                ])
                response = self.bridge.update(self.collection_name, conditions, update_data, "mongodb_cached")
                result = json.loads(response)
                if not result.get("success"):
                    print(f"âš ï¸ æ›´æ–°ç¼“å­˜ç”¨æˆ·å¤±è´¥: {result.get('error')}")
            
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æµ‹è¯•éç¼“å­˜æ•°æ®åº“çš„æ›´æ–°æ“ä½œï¼ˆæ›´æ–°ç›¸åŒçš„ç”¨æˆ·ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
            start_time = time.time()
            for i in range(1, 11):  # æ›´æ–°10ä¸ªç”¨æˆ·
                conditions = json.dumps([
                    {"field": "_id", "operator": "Eq", "value": f"cached_user_{i:03d}"}  # æ›´æ–°ç›¸åŒçš„ç”¨æˆ·
                ])
                response = self.bridge.update(self.collection_name, conditions, update_data, "mongodb_non_cached")
                result = json.loads(response)
                if not result.get("success"):
                    print(f"âš ï¸ æ›´æ–°éç¼“å­˜ç”¨æˆ·å¤±è´¥: {result.get('error')}")
            
            non_cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            result = PerformanceResult.new(
                "æ›´æ–°æ“ä½œ (10æ¬¡)",
                cached_duration,
                non_cached_duration
            )
            
            print(f"  âœ… ç¼“å­˜æ›´æ–°æ“ä½œ: {cached_duration:.2f}ms")
            print(f"  âœ… éç¼“å­˜æ›´æ–°æ“ä½œ: {non_cached_duration:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def _test_simple_id_queries(self) -> bool:
        """æµ‹è¯•ç®€å•IDæŸ¥è¯¢æ€§èƒ½ï¼ˆæœ€èƒ½ä½“ç°ç¼“å­˜ä¼˜åŠ¿ï¼‰"""
        print("\nğŸ” æµ‹è¯•ç®€å•IDæŸ¥è¯¢æ€§èƒ½ï¼ˆæœ€èƒ½ä½“ç°ç¼“å­˜ä¼˜åŠ¿ï¼‰...")
        
        try:
            query_count = 500  # å¢åŠ æŸ¥è¯¢æ¬¡æ•°ä»¥æ›´å¥½åœ°ä½“ç°ç¼“å­˜ä¼˜åŠ¿
            
            # æµ‹è¯•ç¼“å­˜æ•°æ®åº“çš„IDæŸ¥è¯¢
            start_time = time.time()
            for i in range(1, query_count + 1):
                user_id = f"cached_user_{(i % 100) + 1:03d}"  # å¾ªç¯æŸ¥è¯¢å‰100ä¸ªç”¨æˆ·
                self.bridge.find_by_id(self.collection_name, user_id, "mongodb_cached")
            
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æµ‹è¯•éç¼“å­˜æ•°æ®åº“çš„IDæŸ¥è¯¢
            start_time = time.time()
            for i in range(1, query_count + 1):
                user_id = f"cached_user_{(i % 100) + 1:03d}"  # æŸ¥è¯¢ç›¸åŒçš„ç”¨æˆ·ID
                self.bridge.find_by_id(self.collection_name, user_id, "mongodb_non_cached")
            
            non_cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # è®¡ç®—å¹³å‡å•æ¬¡æŸ¥è¯¢æ—¶é—´
            avg_cached_time = cached_duration / query_count
            avg_non_cached_time = non_cached_duration / query_count
            
            result = PerformanceResult.new(
                f"ç®€å•IDæŸ¥è¯¢ ({query_count}æ¬¡)",
                avg_cached_time,
                avg_non_cached_time
            ).with_cache_hit_rate(95.0)  # é¢„æœŸç¼“å­˜å‘½ä¸­ç‡95%
            
            print(f"  âœ… ç¼“å­˜æ€»è€—æ—¶: {cached_duration:.2f}ms")
            print(f"  âœ… éç¼“å­˜æ€»è€—æ—¶: {non_cached_duration:.2f}ms")
            print(f"  âœ… å¹³å‡å•æ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜ï¼‰: {avg_cached_time:.2f}ms")
            print(f"  âœ… å¹³å‡å•æ¬¡æŸ¥è¯¢ï¼ˆéç¼“å­˜ï¼‰: {avg_non_cached_time:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            print(f"  ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {result.cache_hit_rate:.1f}%")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ ç®€å•IDæŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        try:
            # 1. è®¾ç½®æµ‹è¯•æ•°æ®
            if not self.setup_test_data():
                return False
            
            # 2. é¢„çƒ­ç¼“å­˜
            if not self.warmup_cache():
                return False
            
            # 3. è¿è¡Œå„é¡¹æµ‹è¯•
            if not self.test_query_operations():
                return False
            
            # 4. ç®€å•IDæŸ¥è¯¢æµ‹è¯•ï¼ˆæœ€èƒ½ä½“ç°ç¼“å­˜ä¼˜åŠ¿ï¼‰
            if not self._test_simple_id_queries():
                return False
            
            # 5. é‡å¤æŸ¥è¯¢æµ‹è¯•ï¼ˆæœ€èƒ½ä½“ç°ç¼“å­˜ä¼˜åŠ¿ï¼‰
            if not self.test_repeated_queries():
                return False
            
            # 6. æ‰¹é‡æŸ¥è¯¢æµ‹è¯•
            if not self.test_batch_queries():
                return False
            
            # 7. æ›´æ–°æ“ä½œæµ‹è¯•
            if not self.test_update_operations():
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def display_results(self):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»"""
        print("\nğŸ“Š ==================== MongoDBæ€§èƒ½æµ‹è¯•ç»“æœæ±‡æ€» ====================")
        print(f"{'æ“ä½œç±»å‹':<35} {'å¸¦ç¼“å­˜(ms)':<15} {'ä¸å¸¦ç¼“å­˜(ms)':<15} {'æå‡å€æ•°':<10} {'ç¼“å­˜å‘½ä¸­ç‡':<10}")
        print("-" * 90)
        
        total_improvement = 0.0
        count = 0
        
        for result in self.results:
            cache_hit_str = f"{result.cache_hit_rate:.1f}%" if result.cache_hit_rate else "N/A"
            
            print(
                f"{result.operation:<35} "
                f"{result.with_cache:<15.2f} "
                f"{result.without_cache:<15.2f} "
                f"{result.improvement_ratio:<10.2f} "
                f"{cache_hit_str:<10}"
            )
            
            total_improvement += result.improvement_ratio
            count += 1
        
        print("-" * 90)
        
        if count > 0:
            avg_improvement = total_improvement / count
            print(f"ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.2f}x")
            
            if avg_improvement > 2.0:
                print("ğŸ‰ ç¼“å­˜æ˜¾è‘—æå‡äº†MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½ï¼")
            elif avg_improvement > 1.5:
                print("âœ… ç¼“å­˜é€‚åº¦æå‡äº†MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½ã€‚")
            else:
                print("âš ï¸ ç¼“å­˜å¯¹æ€§èƒ½æå‡æœ‰é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç¼“å­˜ç­–ç•¥ã€‚")
        
        print("\nğŸ’¡ MongoDBæ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print("   â€¢ MongoDBçš„ç½‘ç»œå»¶è¿Ÿä½¿å¾—ç¼“å­˜æ•ˆæœæ›´åŠ æ˜æ˜¾")
        print("   â€¢ å¯¹äºé¢‘ç¹æŸ¥è¯¢çš„æ–‡æ¡£ï¼Œç¼“å­˜èƒ½æ˜¾è‘—æå‡æ€§èƒ½")
        print("   â€¢ é‡å¤æŸ¥è¯¢åœºæ™¯ä¸‹ï¼Œç¼“å­˜å‘½ä¸­ç‡è¶Šé«˜ï¼Œæ€§èƒ½æå‡è¶Šæ˜æ˜¾")
        print("   â€¢ å¤æ‚èšåˆæŸ¥è¯¢çš„ç¼“å­˜æ•ˆæœå°¤å…¶æ˜¾è‘—")
        print("   â€¢ å¯æ ¹æ®å®é™…ä¸šåŠ¡åœºæ™¯è°ƒæ•´ç¼“å­˜ TTL å’Œå®¹é‡é…ç½®")
        
        print("\nğŸ”§ MongoDBç¼“å­˜é…ç½®ä¿¡æ¯ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ):")
        print("   â€¢ ç¼“å­˜ç­–ç•¥: LRU")
        print("   â€¢ L1 ç¼“å­˜å®¹é‡: 10000 æ¡è®°å½•")
        print("   â€¢ L1 ç¼“å­˜å†…å­˜é™åˆ¶: 1000 MB")
        print("   â€¢ L2 ç¼“å­˜ç£ç›˜é™åˆ¶: 4000 MB")
        print("   â€¢ é»˜è®¤ TTL: 1 å°æ—¶")
        print("   â€¢ æœ€å¤§ TTL: 4 å°æ—¶")
        print("   â€¢ å‹ç¼©ç®—æ³•: ç¦ç”¨ (å‡å°‘CPUå¼€é”€)")
        print("   â€¢ ç»Ÿè®¡æ”¶é›†: ç¦ç”¨ (å‡å°‘æ€§èƒ½å¼€é”€)")
        print("   â€¢ WAL: ç¦ç”¨ (å‡å°‘ç£ç›˜I/Oå¼€é”€)")
        
        print("\nğŸŒ MongoDBè¿æ¥é…ç½®:")
        print("   â€¢ ä¸»æœº: db0.0ldm0s.net:27017")
        print("   â€¢ æ•°æ®åº“: testdb")
        print("   â€¢ TLS: å¯ç”¨")
        print("   â€¢ ZSTDå‹ç¼©: å¯ç”¨ï¼ˆçº§åˆ«3ï¼Œé˜ˆå€¼1024å­—èŠ‚ï¼‰")
        print(f"   â€¢ æµ‹è¯•é›†åˆ: {self.collection_name}")
    
    def cleanup_resources(self):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶å’Œæ•°æ®ï¼ˆå®ç° GracefulShutdownMixin çš„æŠ½è±¡æ–¹æ³•ï¼‰"""
        print("ğŸ§¹ æ¸…ç† MongoDB æµ‹è¯•æ•°æ®...")
        
        try:
            # æ¸…ç†æµ‹è¯•é›†åˆæ•°æ®ï¼Œæ·»åŠ è¶…æ—¶é™åˆ¶
            if self.bridge:
                try:
                    # è®¾ç½®æ¸…ç†æ“ä½œçš„è¶…æ—¶æ—¶é—´
                    cleanup_start = time.time()
                    cleanup_timeout = 5  # 5ç§’è¶…æ—¶
                    
                    # åˆ é™¤ç¼“å­˜æ•°æ®åº“ä¸­çš„æµ‹è¯•æ•°æ®
                    if time.time() - cleanup_start < cleanup_timeout:
                        delete_conditions = json.dumps([
                            {"field": "_id", "operator": "Contains", "value": "cached_user_"}
                        ])
                        self.bridge.delete(self.collection_name, delete_conditions, "mongodb_cached")
                    
                    # åˆ é™¤éç¼“å­˜æ•°æ®åº“ä¸­çš„æµ‹è¯•æ•°æ®
                    if time.time() - cleanup_start < cleanup_timeout:
                        delete_conditions = json.dumps([
                            {"field": "_id", "operator": "Contains", "value": "non_cached_user_"}
                        ])
                        self.bridge.delete(self.collection_name, delete_conditions, "mongodb_non_cached")
                    
                    print(f"  âœ… å·²æ¸…ç†MongoDBæµ‹è¯•é›†åˆ: {self.collection_name}")
                except Exception as e:
                    print(f"  âš ï¸  æ¸…ç†MongoDBæµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            
            print("âœ… MongoDB æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    def cleanup(self):
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨ä¼˜é›…å…³é—­"""
        self.shutdown()


def display_version_info():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    try:
        version = get_version()
        info = get_info()
        name = get_name()
        
        print(f"åº“åç§°: {name}")
        print(f"ç‰ˆæœ¬å·: {version}")
        print(f"åº“ä¿¡æ¯: {info}")
    except Exception as e:
        print(f"è·å–ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")


@with_graceful_shutdown(ShutdownConfig(verbose_logging=True))
def main():
    """ä¸»å‡½æ•°"""
    global test_instance
    
    print("ğŸš€ RatQuickDB Python MongoDB ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=============================================")
    
    # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    display_version_info()
    print()
    
    # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•
    test = MongoDbCachePerformanceTest()
    test_instance = test  # è®¾ç½®å…¨å±€å®ä¾‹ç”¨äºä¿¡å·å¤„ç†
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
        if not test.initialize():
            return 1
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        if not test.run_all_tests():
            return 1
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        test.display_results()
        
        print("\nğŸ¯ MongoDBæµ‹è¯•å®Œæˆï¼æ„Ÿè°¢ä½¿ç”¨ RatQuickDB MongoDB ç¼“å­˜åŠŸèƒ½ã€‚")
        return 0
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ”¶åˆ°é”®ç›˜ä¸­æ–­ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        with shutdown_lock:
            if not shutdown_requested:
                test.shutdown()
                print("ğŸ‘‹ ç¨‹åºå·²ä¼˜é›…å…³é—­")
        return 0
    except Exception as e:
        print(f"âš ï¸ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        try:
            test.shutdown()
        except:
            pass
        return 1
    finally:
        # ä¼˜é›…å…³é—­ä¼šè‡ªåŠ¨å¤„ç†èµ„æºæ¸…ç†
        try:
            test.shutdown()
        except:
            pass
        test_instance = None


if __name__ == "__main__":
    exit(main())