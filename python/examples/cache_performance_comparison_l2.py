#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""RAT QuickDB Python ç¼“å­˜æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹

æœ¬ç¤ºä¾‹å¯¹æ¯”å¯ç”¨ç¼“å­˜å’Œæœªå¯ç”¨ç¼“å­˜çš„æ•°æ®åº“æ“ä½œæ€§èƒ½å·®å¼‚
ä½¿ç”¨ SQLite æ•°æ®åº“è¿›è¡Œæµ‹è¯•

åŸºäº Rust ç‰ˆæœ¬çš„ç¼“å­˜æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹æ”¹å†™
"""

import json
import time
import os
import shutil
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

try:
    import rat_quickdb_py
    from rat_quickdb_py import (
        create_db_queue_bridge,
        get_version,
        get_info,
        get_name,
        PyCacheConfig,
        PyL1CacheConfig,
        PyL2CacheConfig,
        PyTtlConfig,
        PyCompressionConfig,
    )
except ImportError as e:
    print(f"é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ rat_quickdb_py æ¨¡å—: {e}")
    print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… rat-quickdb-py åŒ…")
    print("å®‰è£…å‘½ä»¤ï¼šmaturin develop")
    exit(1)


@dataclass
class TestUser:
    """æµ‹è¯•ç”¨æˆ·æ•°æ®ç»“æ„"""
    id: str
    name: str
    email: str
    age: int
    created_at: str
    
    @classmethod
    def new(cls, user_id: str, name: str, email: str, age: int) -> 'TestUser':
        return cls(
            id=user_id,
            name=name,
            email=email,
            age=age,
            created_at=datetime.now(timezone.utc).isoformat()
        )
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps({
            "id": self.id,
            "name": self.name,
            "email": self.email,
            "age": self.age,
            "created_at": self.created_at
        })


@dataclass
class PerformanceResult:
    """æ€§èƒ½æµ‹è¯•ç»“æœ"""
    operation: str
    with_cache: float  # æ¯«ç§’
    without_cache: float  # æ¯«ç§’
    improvement_ratio: float
    cache_hit_rate: Optional[float] = None
    
    @classmethod
    def new(cls, operation: str, with_cache: float, without_cache: float) -> 'PerformanceResult':
        improvement_ratio = without_cache / with_cache if with_cache > 0 else 1.0
        return cls(
            operation=operation,
            with_cache=with_cache,
            without_cache=without_cache,
            improvement_ratio=improvement_ratio
        )
    
    def with_cache_hit_rate(self, hit_rate: float) -> 'PerformanceResult':
        self.cache_hit_rate = hit_rate
        return self


class CachePerformanceTest:
    """ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    
    def __init__(self):
        self.bridge = None
        self.results: List[PerformanceResult] = []
        self.test_data_dir = "./test_data"
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸš€ åˆå§‹åŒ–ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•ç¯å¢ƒ...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
            os.makedirs(self.test_data_dir, exist_ok=True)
            
            # åˆ›å»ºæ•°æ®åº“é˜Ÿåˆ—æ¡¥æ¥å™¨
            self.bridge = create_db_queue_bridge()
            
            # æ·»åŠ å¸¦ç¼“å­˜çš„æ•°æ®åº“
            self._add_cached_database()
            
            # æ·»åŠ ä¸å¸¦ç¼“å­˜çš„æ•°æ®åº“
            self._add_non_cached_database()
            
            # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ•°æ®ï¼ˆåˆ é™¤è¡¨ï¼‰
            self._cleanup_existing_tables()
            
            print("âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _create_cached_config(self) -> PyCacheConfig:
        """åˆ›å»ºå¸¦ç¼“å­˜çš„é…ç½®ï¼ˆå¯ç”¨L2ç¼“å­˜ï¼‰"""
        cache_config = PyCacheConfig()
        cache_config.enable()
        cache_config.strategy = "lru"

        # L1ç¼“å­˜é…ç½®
        l1_config = PyL1CacheConfig(1000)  # æœ€å¤§å®¹é‡1000æ¡è®°å½•
        l1_config.max_memory_mb = 50  # æœ€å¤§å†…å­˜50MB
        l1_config.enable_stats = True  # å¯ç”¨ç»Ÿè®¡
        cache_config.l1_config = l1_config

        # L2ç¼“å­˜é…ç½®
        l2_config = PyL2CacheConfig("./cache_l2_test")  # L2ç¼“å­˜å­˜å‚¨è·¯å¾„
        l2_config.max_disk_mb = 500  # æœ€å¤§500MBç£ç›˜ç©ºé—´
        l2_config.compression_level = 3  # å‹ç¼©çº§åˆ«
        l2_config.enable_wal = True  # å¯ç”¨WAL
        l2_config.clear_on_startup = False  # å¯åŠ¨æ—¶ä¸æ¸…ç©ºç¼“å­˜ç›®å½•
        cache_config.l2_config = l2_config

        # TTLé…ç½®
        ttl_config = PyTtlConfig(300)  # é»˜è®¤TTL 5åˆ†é’Ÿ
        ttl_config.max_ttl_secs = 3600  # æœ€å¤§TTL 1å°æ—¶
        ttl_config.check_interval_secs = 60  # æ£€æŸ¥é—´éš”1åˆ†é’Ÿ
        cache_config.ttl_config = ttl_config

        # å‹ç¼©é…ç½®
        compression_config = PyCompressionConfig("gzip")
        compression_config.enabled = False  # æš‚æ—¶ç¦ç”¨å‹ç¼©
        compression_config.threshold_bytes = 1024
        cache_config.compression_config = compression_config

        return cache_config
    
    def _add_cached_database(self):
        """æ·»åŠ å¸¦ç¼“å­˜çš„æ•°æ®åº“"""
        cache_config = self._create_cached_config()
        
        response = self.bridge.add_sqlite_database(
            alias="cached_db",
            path=f"{self.test_data_dir}/cache_performance_cached.db",
            max_connections=10,
            min_connections=1,
            connection_timeout=30,
            idle_timeout=600,
            max_lifetime=3600,
            cache_config=cache_config
        )
        
        result = json.loads(response)
        if not result.get("success"):
            raise Exception(f"æ·»åŠ ç¼“å­˜æ•°æ®åº“å¤±è´¥: {result.get('error')}")
    
    def _add_non_cached_database(self):
        """æ·»åŠ ä¸å¸¦ç¼“å­˜çš„æ•°æ®åº“"""
        response = self.bridge.add_sqlite_database(
            alias="non_cached_db",
            path=f"{self.test_data_dir}/cache_performance_non_cached.db",
            max_connections=10,
            min_connections=1,
            connection_timeout=30,
            idle_timeout=600,
            max_lifetime=3600,
            cache_config=None  # ä¸ä½¿ç”¨ç¼“å­˜
        )
        
        result = json.loads(response)
        if not result.get("success"):
            raise Exception(f"æ·»åŠ éç¼“å­˜æ•°æ®åº“å¤±è´¥: {result.get('error')}")
    
    def _cleanup_existing_tables(self):
        """æ¸…ç†ç°æœ‰çš„æµ‹è¯•è¡¨"""
        print("ğŸ§¹ æ¸…ç†ç°æœ‰çš„æµ‹è¯•è¡¨...")
        
        try:
            # åˆ é™¤ç¼“å­˜æ•°æ®åº“ä¸­çš„usersè¡¨æ•°æ®
            try:
                delete_conditions = json.dumps([])
                response = self.bridge.delete("users", delete_conditions, "cached_db")
                result = json.loads(response)
                if result.get("success"):
                    print("  âœ… å·²æ¸…ç†ç¼“å­˜æ•°æ®åº“ä¸­çš„usersè¡¨æ•°æ®")
            except Exception as e:
                print(f"  âš ï¸ æ¸…ç†ç¼“å­˜æ•°æ®åº“è¡¨æ•°æ®å¤±è´¥ï¼ˆå¯èƒ½è¡¨ä¸å­˜åœ¨ï¼‰: {e}")
            
            # åˆ é™¤éç¼“å­˜æ•°æ®åº“ä¸­çš„usersè¡¨æ•°æ®
            try:
                delete_conditions = json.dumps([])
                response = self.bridge.delete("users", delete_conditions, "non_cached_db")
                result = json.loads(response)
                if result.get("success"):
                    print("  âœ… å·²æ¸…ç†éç¼“å­˜æ•°æ®åº“ä¸­çš„usersè¡¨æ•°æ®")
            except Exception as e:
                print(f"  âš ï¸ æ¸…ç†éç¼“å­˜æ•°æ®åº“è¡¨æ•°æ®å¤±è´¥ï¼ˆå¯èƒ½è¡¨ä¸å­˜åœ¨ï¼‰: {e}")
                
        except Exception as e:
            print(f"  âš ï¸ æ¸…ç†æµ‹è¯•è¡¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    def setup_test_data(self) -> bool:
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        print("\nğŸ”§ è®¾ç½®æµ‹è¯•æ•°æ®...")
        
        try:
            # åŸºç¡€æµ‹è¯•ç”¨æˆ·
            test_users = [
                TestUser.new("user1", "å¼ ä¸‰", "zhangsan@example.com", 25),
                TestUser.new("user2", "æå››", "lisi@example.com", 30),
                TestUser.new("user3", "ç‹äº”", "wangwu@example.com", 28),
                TestUser.new("user4", "èµµå…­", "zhaoliu@example.com", 35),
                TestUser.new("user5", "é’±ä¸ƒ", "qianqi@example.com", 22),
            ]
            
            # æ‰¹é‡ç”¨æˆ·æ•°æ®
            batch_users = [
                TestUser.new(
                    f"batch_user_{i}",
                    f"æ‰¹é‡ç”¨æˆ·{i}",
                    f"batch{i}@example.com",
                    20 + (i % 30)
                )
                for i in range(6, 26)
            ]
            
            all_users = test_users + batch_users
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°ç¼“å­˜æ•°æ®åº“
            for user in all_users:
                response = self.bridge.create("users", user.to_json(), "cached_db")
                result = json.loads(response)
                if not result.get("success"):
                    print(f"âš ï¸ åˆ›å»ºç”¨æˆ·æ•°æ®å¤±è´¥: {result.get('error')}")
            
            print(f"  âœ… åˆ›å»ºäº† {len(all_users)} æ¡æµ‹è¯•è®°å½•")
            return True
            
        except Exception as e:
            print(f"âŒ è®¾ç½®æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return False
    
    def warmup_cache(self) -> bool:
        """ç¼“å­˜é¢„çƒ­"""
        print("\nğŸ”¥ ç¼“å­˜é¢„çƒ­...")
        
        try:
            # é¢„çƒ­æŸ¥è¯¢ - æŸ¥æ‰¾å¹´é¾„åœ¨25-35ä¹‹é—´ä¸”å§“ååŒ…å«ç‰¹å®šå­—ç¬¦çš„ç”¨æˆ·
            query_conditions = json.dumps([
                {"field": "age", "operator": "Gte", "value": 25},
                {"field": "age", "operator": "Lte", "value": 35},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "@example.com"}
            ])
            
            # é¢„çƒ­æŸ¥è¯¢
            self.bridge.find("users", query_conditions, "cached_db")
            
            # æŒ‰IDæŸ¥è¯¢é¢„çƒ­
            self.bridge.find_by_id("users", "user1", "cached_db")
            self.bridge.find_by_id("users", "user2", "cached_db")
            
            print("  âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
            return False
    
    def test_query_operations(self) -> bool:
        """æµ‹è¯•æŸ¥è¯¢æ“ä½œæ€§èƒ½"""
        print("\nğŸ” æµ‹è¯•æŸ¥è¯¢æ“ä½œæ€§èƒ½...")
        
        try:
            # æ„å»ºå¤æ‚æŸ¥è¯¢æ¡ä»¶ - æŸ¥æ‰¾ç‰¹å®šç”¨æˆ·ä¸”å¹´é¾„ç¬¦åˆæ¡ä»¶
            query_conditions = json.dumps([
                {"field": "name", "operator": "Eq", "value": "å¼ ä¸‰"},
                {"field": "age", "operator": "Gte", "value": 20},
                {"field": "age", "operator": "Lte", "value": 50},
                {"field": "email", "operator": "Contains", "value": "@example.com"}
            ])
            
            # ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆå†·å¯åŠ¨ï¼Œä»æ•°æ®åº“è¯»å–ï¼‰
            start_time = time.time()
            self.bridge.find("users", query_conditions, "cached_db")
            first_query_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
            start_time = time.time()
            self.bridge.find("users", query_conditions, "cached_db")
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            result = PerformanceResult.new(
                "å•æ¬¡æŸ¥è¯¢æ“ä½œ",
                cached_duration,
                first_query_duration
            )
            
            print(f"  âœ… é¦–æ¬¡æŸ¥è¯¢ï¼ˆæ•°æ®åº“ï¼‰: {first_query_duration:.2f}ms")
            print(f"  âœ… ç¼“å­˜æŸ¥è¯¢: {cached_duration:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_repeated_queries(self) -> bool:
        """æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­æµ‹è¯•ï¼‰"""
        print("\nğŸ”„ æµ‹è¯•é‡å¤æŸ¥è¯¢æ€§èƒ½ï¼ˆç¼“å­˜å‘½ä¸­æµ‹è¯•ï¼‰...")
        
        try:
            # æ„å»ºå¤šæ¡ä»¶æŸ¥è¯¢ - æŸ¥æ‰¾å¹´é¾„å¤§äº20ä¸”å§“ååŒ…å«ç‰¹å®šå­—ç¬¦çš„æ´»è·ƒç”¨æˆ·
            query_conditions = json.dumps([
                {"field": "age", "operator": "Gt", "value": 20},
                {"field": "age", "operator": "Lt", "value": 40},
                {"field": "name", "operator": "Contains", "value": "ç”¨æˆ·"},
                {"field": "email", "operator": "Contains", "value": "batch"}
            ])
            
            query_count = 10
            
            # é¦–æ¬¡æŸ¥è¯¢ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
            self.bridge.find("users", query_conditions, "cached_db")
            
            # æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆåº”è¯¥ä»ç¼“å­˜è¯»å–ï¼‰
            start_time = time.time()
            for _ in range(query_count):
                self.bridge.find("users", query_conditions, "cached_db")
                time.sleep(0.005)  # çŸ­æš‚å»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®åœºæ™¯
            
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # è®¡ç®—å¹³å‡å•æ¬¡æŸ¥è¯¢æ—¶é—´
            avg_cached_time = cached_duration / query_count
            estimated_db_time = 50.0  # ä¼°ç®—æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            
            result = PerformanceResult.new(
                f"é‡å¤æŸ¥è¯¢ ({query_count}æ¬¡)",
                avg_cached_time,
                estimated_db_time
            ).with_cache_hit_rate(95.0)  # å‡è®¾95%çš„ç¼“å­˜å‘½ä¸­ç‡
            
            print(f"  âœ… æ€»è€—æ—¶: {cached_duration:.2f}ms")
            print(f"  âœ… å¹³å‡å•æ¬¡æŸ¥è¯¢: {avg_cached_time:.2f}ms")
            print(f"  ğŸ“ˆ é¢„ä¼°æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            print(f"  ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {result.cache_hit_rate:.1f}%")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ é‡å¤æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_batch_queries(self) -> bool:
        """æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½"""
        print("\nğŸ“¦ æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½...")
        
        try:
            user_ids = ["user1", "user2", "user3", "user4", "user5"]
            
            # é¦–æ¬¡æ‰¹é‡æŸ¥è¯¢ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
            start_time = time.time()
            for user_id in user_ids:
                self.bridge.find_by_id("users", user_id, "cached_db")
            first_batch_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # ç¬¬äºŒæ¬¡æ‰¹é‡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
            start_time = time.time()
            for user_id in user_ids:
                self.bridge.find_by_id("users", user_id, "cached_db")
            cached_duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            result = PerformanceResult.new(
                f"æ‰¹é‡IDæŸ¥è¯¢ ({len(user_ids)}æ¡è®°å½•)",
                cached_duration,
                first_batch_duration
            )
            
            print(f"  âœ… é¦–æ¬¡æ‰¹é‡æŸ¥è¯¢: {first_batch_duration:.2f}ms")
            print(f"  âœ… ç¼“å­˜æ‰¹é‡æŸ¥è¯¢: {cached_duration:.2f}ms")
            print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {result.improvement_ratio:.2f}x")
            
            self.results.append(result)
            return True
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        try:
            # 1. è®¾ç½®æµ‹è¯•æ•°æ®
            if not self.setup_test_data():
                return False
            
            # 2. é¢„çƒ­ç¼“å­˜
            if not self.warmup_cache():
                return False
            
            # 3. è¿è¡Œå„é¡¹æµ‹è¯•
            if not self.test_query_operations():
                return False
            
            if not self.test_repeated_queries():
                return False
            
            if not self.test_batch_queries():
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def display_results(self):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»"""
        print("\nğŸ“Š ==================== æ€§èƒ½æµ‹è¯•ç»“æœæ±‡æ€» ====================")
        print(f"{'æ“ä½œç±»å‹':<25} {'å¸¦ç¼“å­˜(ms)':<15} {'ä¸å¸¦ç¼“å­˜(ms)':<15} {'æå‡å€æ•°':<10} {'ç¼“å­˜å‘½ä¸­ç‡':<10}")
        print("-" * 80)
        
        total_improvement = 0.0
        count = 0
        
        for result in self.results:
            cache_hit_str = f"{result.cache_hit_rate:.1f}%" if result.cache_hit_rate else "N/A"
            
            print(
                f"{result.operation:<25} "
                f"{result.with_cache:<15.2f} "
                f"{result.without_cache:<15.2f} "
                f"{result.improvement_ratio:<10.2f} "
                f"{cache_hit_str:<10}"
            )
            
            total_improvement += result.improvement_ratio
            count += 1
        
        print("-" * 80)
        
        if count > 0:
            avg_improvement = total_improvement / count
            print(f"ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.2f}x")
            
            if avg_improvement > 1.5:
                print("ğŸ‰ ç¼“å­˜æ˜¾è‘—æå‡äº†æ•°æ®åº“æ“ä½œæ€§èƒ½ï¼")
            elif avg_improvement > 1.1:
                print("âœ… ç¼“å­˜é€‚åº¦æå‡äº†æ•°æ®åº“æ“ä½œæ€§èƒ½ã€‚")
            else:
                print("âš ï¸ ç¼“å­˜å¯¹æ€§èƒ½æå‡æœ‰é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç¼“å­˜ç­–ç•¥ã€‚")
        
        print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print("   â€¢ å¯¹äºé¢‘ç¹æŸ¥è¯¢çš„æ•°æ®ï¼Œç¼“å­˜èƒ½æ˜¾è‘—æå‡æ€§èƒ½")
        print("   â€¢ é‡å¤æŸ¥è¯¢åœºæ™¯ä¸‹ï¼Œç¼“å­˜å‘½ä¸­ç‡è¶Šé«˜ï¼Œæ€§èƒ½æå‡è¶Šæ˜æ˜¾")
        print("   â€¢ å†™æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ï¼‰çš„æ€§èƒ½æå‡ç›¸å¯¹æœ‰é™")
        print("   â€¢ å¯æ ¹æ®å®é™…ä¸šåŠ¡åœºæ™¯è°ƒæ•´ç¼“å­˜ TTL å’Œå®¹é‡é…ç½®")
        
        print("\nğŸ”§ ç¼“å­˜é…ç½®ä¿¡æ¯:")
        print("   â€¢ ç¼“å­˜ç­–ç•¥: LRU")
        print("   â€¢ L1 ç¼“å­˜å®¹é‡: 1000 æ¡è®°å½•")
        print("   â€¢ L1 ç¼“å­˜å†…å­˜é™åˆ¶: 50 MB")
        print("   â€¢ é»˜è®¤ TTL: 5 åˆ†é’Ÿ")
        print("   â€¢ æœ€å¤§ TTL: 1 å°æ—¶")
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        
        try:
            if os.path.exists(self.test_data_dir):
                shutil.rmtree(self.test_data_dir)
                print(f"ğŸ—‘ï¸  å·²æ¸…ç†æµ‹è¯•ç›®å½•: {self.test_data_dir}")
            
            print("ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}")


def display_version_info():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    try:
        version = get_version()
        info = get_info()
        name = get_name()
        
        print(f"åº“åç§°: {name}")
        print(f"ç‰ˆæœ¬å·: {version}")
        print(f"åº“ä¿¡æ¯: {info}")
    except Exception as e:
        print(f"è·å–ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ RatQuickDB Python ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆL1 + L2 ç¼“å­˜ï¼‰")
    print("=====================================")
    
    # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    display_version_info()
    print()
    
    # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•
    test = CachePerformanceTest()
    
    try:
        # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ–‡ä»¶
        test.cleanup()
        
        # åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
        if not test.initialize():
            return 1
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        if not test.run_all_tests():
            return 1
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        test.display_results()
        
        print("\nğŸ¯ æµ‹è¯•å®Œæˆï¼æ„Ÿè°¢ä½¿ç”¨ RatQuickDB ç¼“å­˜åŠŸèƒ½ã€‚")
        return 0
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test.cleanup()


if __name__ == "__main__":
    exit(main())